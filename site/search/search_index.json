{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PMTaro User Manual V0.1.0 Menu 1 Introduction 2 Software Description 3 Installation and Setup 4 Software Page Overview 5 Welcome Page 6 Dataset Parse Page 7 Dataset Detail Page 8 Dataset Browing Page 9 Plugin Page 10 Pipelines Page (MPF Post-processing)","title":"Home"},{"location":"#pmtaro-user-manual-v010","text":"","title":"PMTaro User Manual V0.1.0"},{"location":"#menu","text":"1 Introduction 2 Software Description 3 Installation and Setup 4 Software Page Overview 5 Welcome Page 6 Dataset Parse Page 7 Dataset Detail Page 8 Dataset Browing Page 9 Plugin Page 10 Pipelines Page (MPF Post-processing)","title":"Menu"},{"location":"1.1_reset_camera/","text":"1.1 Reset Camera Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings.","title":"1.1 Reset Camera"},{"location":"1.1_reset_camera/#11-reset-camera","text":"Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings.","title":"1.1 Reset Camera"},{"location":"1.1_varieties_of_nodes/","text":"1.1 Varieties of Nodes The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file.","title":"1.1 Varieties of Nodes"},{"location":"1.1_varieties_of_nodes/#11-varieties-of-nodes","text":"The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file.","title":"1.1 Varieties of Nodes"},{"location":"1.2_add_node/","text":"1.2 Add Node Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow.","title":"1.2 Add Node"},{"location":"1.2_add_node/#12-add-node","text":"Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow.","title":"1.2 Add Node"},{"location":"1.2_data_info/","text":"1.2 Data Info In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"1.2 Data Info"},{"location":"1.2_data_info/#12-data-info","text":"In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"1.2 Data Info"},{"location":"10_pipelines_page_mpf_post-processing/","text":"10 Pipelines Page (MPF Post-processing) The MPF post-processing pipeline module offers users a versatile and flexible tool for customizing and executing data processing workflows through pipeline configuration and data management. Currently, this module is primarily utilized for MPF post-processing, providing multiple pipelines tailored for specific post-processing of MPF data. The plugin module allows users to design and upload their own data processing algorithms as plugins to meet specific standards. Users can integrate these plugins, each with unique functionalities, into coherent pipelines within the platform. This enables users to process data individually or in batch mode while maintaining supervision over the derivatives and results generated during the processing operations. 10.1 New Pipeline In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration. 10.2 Pipeline Control Panel Located at the bottom of the interface, this section provides pipeline execution controls and management functions. 10.2.1 Execute Pipeline 10.2.2 Rename Pipeline 10.2.3 Save Change 10.2.4 Export Pipeline 10.3 View Control Panel Situated in the lower right corner, this section manages display settings and visualization options. 10.3.1 Zoom In / Out 10.3.2 Fit View 10.3.3 Select Mode 10.3.4 Toggle Link Visibility 10.4 Smooth Processing Pipeline (Auto) The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node. 10.5 MPF Phase Map Calculation Pipeline (Auto) The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask. 10.6 RMPFSL Map Calculation Pipeline (Auto) The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps. 10.7 MPF Map Calculation Pipeline (Auto) The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10 Pipelines Page (MPF Post-processing)"},{"location":"10_pipelines_page_mpf_post-processing/#10-pipelines-page-mpf-post-processing","text":"The MPF post-processing pipeline module offers users a versatile and flexible tool for customizing and executing data processing workflows through pipeline configuration and data management. Currently, this module is primarily utilized for MPF post-processing, providing multiple pipelines tailored for specific post-processing of MPF data. The plugin module allows users to design and upload their own data processing algorithms as plugins to meet specific standards. Users can integrate these plugins, each with unique functionalities, into coherent pipelines within the platform. This enables users to process data individually or in batch mode while maintaining supervision over the derivatives and results generated during the processing operations.","title":"10 Pipelines Page (MPF Post-processing)"},{"location":"10_pipelines_page_mpf_post-processing/#101-new-pipeline","text":"In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"10.1 New Pipeline"},{"location":"10_pipelines_page_mpf_post-processing/#102-pipeline-control-panel","text":"Located at the bottom of the interface, this section provides pipeline execution controls and management functions.","title":"10.2 Pipeline Control Panel"},{"location":"10_pipelines_page_mpf_post-processing/#1021-execute-pipeline","text":"","title":"10.2.1 Execute Pipeline"},{"location":"10_pipelines_page_mpf_post-processing/#1022-rename-pipeline","text":"","title":"10.2.2 Rename Pipeline"},{"location":"10_pipelines_page_mpf_post-processing/#1023-save-change","text":"","title":"10.2.3 Save Change"},{"location":"10_pipelines_page_mpf_post-processing/#1024-export-pipeline","text":"","title":"10.2.4 Export Pipeline"},{"location":"10_pipelines_page_mpf_post-processing/#103-view-control-panel","text":"Situated in the lower right corner, this section manages display settings and visualization options.","title":"10.3 View Control Panel"},{"location":"10_pipelines_page_mpf_post-processing/#1031-zoom-in-out","text":"","title":"10.3.1 Zoom In / Out"},{"location":"10_pipelines_page_mpf_post-processing/#1032-fit-view","text":"","title":"10.3.2 Fit View"},{"location":"10_pipelines_page_mpf_post-processing/#1033-select-mode","text":"","title":"10.3.3 Select Mode"},{"location":"10_pipelines_page_mpf_post-processing/#1034-toggle-link-visibility","text":"","title":"10.3.4 Toggle Link Visibility"},{"location":"10_pipelines_page_mpf_post-processing/#104-smooth-processing-pipeline-auto","text":"The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"10.4 Smooth Processing Pipeline (Auto)"},{"location":"10_pipelines_page_mpf_post-processing/#105-mpf-phase-map-calculation-pipeline-auto","text":"The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"10.5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"10_pipelines_page_mpf_post-processing/#106-rmpfsl-map-calculation-pipeline-auto","text":"The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"10.6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"10_pipelines_page_mpf_post-processing/#107-mpf-map-calculation-pipeline-auto","text":"The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10.7 MPF Map Calculation Pipeline (Auto)"},{"location":"1_add_folder/","text":"1 Add Folder After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"1 Add Folder"},{"location":"1_add_folder/#1-add-folder","text":"After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"1 Add Folder"},{"location":"1_download_pmtaro_installer_%26_run_setup_wizard/","text":"1 Download PMTaro installer & Run setup wizard Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"1 Download PMTaro installer &amp; Run setup wizard"},{"location":"1_download_pmtaro_installer_%26_run_setup_wizard/#1-download-pmtaro-installer-run-setup-wizard","text":"Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"1 Download PMTaro installer &amp; Run setup wizard"},{"location":"1_image_interface/","text":"1 Image Interface","title":"1 Image Interface"},{"location":"1_image_interface/#1-image-interface","text":"","title":"1 Image Interface"},{"location":"1_introduction/","text":"1 Introduction Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"1 Introduction"},{"location":"1_introduction/#1-introduction","text":"Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"1 Introduction"},{"location":"1_new_dataset/","text":"1 New Dataset To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"1 New Dataset"},{"location":"1_new_dataset/#1-new-dataset","text":"To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"1 New Dataset"},{"location":"1_new_pipeline/","text":"1 New Pipeline In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"1 New Pipeline"},{"location":"1_new_pipeline/#1-new-pipeline","text":"In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"1 New Pipeline"},{"location":"1_node/","text":"1 Node","title":"1 Node"},{"location":"1_node/#1-node","text":"","title":"1 Node"},{"location":"1_reports/","text":"1 Reports In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"1 Reports"},{"location":"1_reports/#1-reports","text":"In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"1 Reports"},{"location":"1_welcome_page/","text":"1 Welcome Page Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"1 Welcome Page"},{"location":"1_welcome_page/#1-welcome-page","text":"Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"1 Welcome Page"},{"location":"2.10_ruler_measurement/","text":"2.10 Ruler (Measurement) Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points.","title":"2.10 Ruler (Measurement)"},{"location":"2.10_ruler_measurement/#210-ruler-measurement","text":"Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points.","title":"2.10 Ruler (Measurement)"},{"location":"2.11_3d_crop/","text":"2.11 3D Crop Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"2.11 3D Crop"},{"location":"2.11_3d_crop/#211-3d-crop","text":"Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"2.11 3D Crop"},{"location":"2.1_execute_pipeline/","text":"2.1 Execute Pipeline","title":"2.1 Execute Pipeline"},{"location":"2.1_execute_pipeline/#21-execute-pipeline","text":"","title":"2.1 Execute Pipeline"},{"location":"2.1_interaction_info_list/","text":"2.1 Interaction Info List In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering.","title":"2.1 Interaction Info List"},{"location":"2.1_interaction_info_list/#21-interaction-info-list","text":"In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering.","title":"2.1 Interaction Info List"},{"location":"2.1_node_status_description/","text":"2.1 Node status description The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"2.1 Node status description"},{"location":"2.1_node_status_description/#21-node-status-description","text":"The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"2.1 Node status description"},{"location":"2.2_layout_selection/","text":"2.2 Layout Selection On this page, users can select the layout interface and achieve 3D reconstruction.","title":"2.2 Layout Selection"},{"location":"2.2_layout_selection/#22-layout-selection","text":"On this page, users can select the layout interface and achieve 3D reconstruction.","title":"2.2 Layout Selection"},{"location":"2.2_node_setting/","text":"2.2 Node Setting Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings.","title":"2.2 Node Setting"},{"location":"2.2_node_setting/#22-node-setting","text":"Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings.","title":"2.2 Node Setting"},{"location":"2.2_rename_pipeline/","text":"2.2 Rename Pipeline","title":"2.2 Rename Pipeline"},{"location":"2.2_rename_pipeline/#22-rename-pipeline","text":"","title":"2.2 Rename Pipeline"},{"location":"2.3_save_change/","text":"2.3 Save Change","title":"2.3 Save Change"},{"location":"2.3_save_change/#23-save-change","text":"","title":"2.3 Save Change"},{"location":"2.3_window_level_contrast/","text":"2.3 Window/Level (Contrast) This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width.","title":"2.3 Window/Level (Contrast)"},{"location":"2.3_window_level_contrast/#23-windowlevel-contrast","text":"This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width.","title":"2.3 Window/Level (Contrast)"},{"location":"2.4_export_pipeline/","text":"2.4 Export Pipeline","title":"2.4 Export Pipeline"},{"location":"2.4_export_pipeline/#24-export-pipeline","text":"","title":"2.4 Export Pipeline"},{"location":"2.4_pan/","text":"2.4 Pan To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view.","title":"2.4 Pan"},{"location":"2.4_pan/#24-pan","text":"To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view.","title":"2.4 Pan"},{"location":"2.5_zoom/","text":"2.5 Zoom To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out.","title":"2.5 Zoom"},{"location":"2.5_zoom/#25-zoom","text":"To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out.","title":"2.5 Zoom"},{"location":"2.6_crosshair/","text":"2.6 Crosshair To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position.","title":"2.6 Crosshair"},{"location":"2.6_crosshair/#26-crosshair","text":"To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position.","title":"2.6 Crosshair"},{"location":"2.7_paint_segmentation/","text":"2.7 Paint (Segmentation) In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image.","title":"2.7 Paint (Segmentation)"},{"location":"2.7_paint_segmentation/#27-paint-segmentation","text":"In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image.","title":"2.7 Paint (Segmentation)"},{"location":"2.8_rectangle_measurement/","text":"2.8 Rectangle (Measurement) In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI.","title":"2.8 Rectangle (Measurement)"},{"location":"2.8_rectangle_measurement/#28-rectangle-measurement","text":"In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI.","title":"2.8 Rectangle (Measurement)"},{"location":"2.9_polygon_measurement/","text":"2.9 Polygon (Measurement) Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area.","title":"2.9 Polygon (Measurement)"},{"location":"2.9_polygon_measurement/#29-polygon-measurement","text":"Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area.","title":"2.9 Polygon (Measurement)"},{"location":"2_configuration/","text":"2 Configuration Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"2 Configuration"},{"location":"2_configuration/#2-configuration","text":"Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"2 Configuration"},{"location":"2_data_interaction_%26_toolbar/","text":"2 Data Interaction & Toolbar","title":"2 Data Interaction &amp; Toolbar"},{"location":"2_data_interaction_%26_toolbar/#2-data-interaction-toolbar","text":"","title":"2 Data Interaction &amp; Toolbar"},{"location":"2_dataset_parse_page/","text":"2 Dataset Parse Page The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"2 Dataset Parse Page"},{"location":"2_dataset_parse_page/#2-dataset-parse-page","text":"The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"2 Dataset Parse Page"},{"location":"2_labels/","text":"2 Labels In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"2 Labels"},{"location":"2_labels/#2-labels","text":"In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"2 Labels"},{"location":"2_pipeline_control_panel/","text":"2 Pipeline Control Panel Located at the bottom of the interface, this section provides pipeline execution controls and management functions.","title":"2 Pipeline Control Panel"},{"location":"2_pipeline_control_panel/#2-pipeline-control-panel","text":"Located at the bottom of the interface, this section provides pipeline execution controls and management functions.","title":"2 Pipeline Control Panel"},{"location":"2_plugin/","text":"2 Plugin To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"2 Plugin"},{"location":"2_plugin/#2-plugin","text":"To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"2 Plugin"},{"location":"2_prepare_dataset/","text":"2 Prepare Dataset After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"2 Prepare Dataset"},{"location":"2_prepare_dataset/#2-prepare-dataset","text":"After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"2 Prepare Dataset"},{"location":"2_recent_dataset/","text":"2 Recent Dataset If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"2 Recent Dataset"},{"location":"2_recent_dataset/#2-recent-dataset","text":"If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"2 Recent Dataset"},{"location":"2_software_description/","text":"2 Software Description Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"2 Software Description"},{"location":"2_software_description/#2-software-description","text":"Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"2 Software Description"},{"location":"3.1_zoom_in___out/","text":"3.1 Zoom In / Out","title":"3.1 Zoom In / Out"},{"location":"3.1_zoom_in___out/#31-zoom-in-out","text":"","title":"3.1 Zoom In / Out"},{"location":"3.2_fit_view/","text":"3.2 Fit View","title":"3.2 Fit View"},{"location":"3.2_fit_view/#32-fit-view","text":"","title":"3.2 Fit View"},{"location":"3.3_select_mode/","text":"3.3 Select Mode","title":"3.3 Select Mode"},{"location":"3.3_select_mode/#33-select-mode","text":"","title":"3.3 Select Mode"},{"location":"3.4_toggle_link_visibility/","text":"3.4 Toggle Link Visibility","title":"3.4 Toggle Link Visibility"},{"location":"3.4_toggle_link_visibility/#34-toggle-link-visibility","text":"","title":"3.4 Toggle Link Visibility"},{"location":"3_dataset_detail_page/","text":"3 Dataset Detail Page The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"3 Dataset Detail Page"},{"location":"3_dataset_detail_page/#3-dataset-detail-page","text":"The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"3 Dataset Detail Page"},{"location":"3_installation_and_setup/","text":"3 Installation and Setup 3.1 Download PMTaro installer & Run setup wizard Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed! 3.2 Configuration Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3 Installation and Setup"},{"location":"3_installation_and_setup/#3-installation-and-setup","text":"","title":"3 Installation and Setup"},{"location":"3_installation_and_setup/#31-download-pmtaro-installer-run-setup-wizard","text":"Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"3.1 Download PMTaro installer &amp; Run setup wizard"},{"location":"3_installation_and_setup/#32-configuration","text":"Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3.2 Configuration"},{"location":"3_pipelines/","text":"3 Pipelines In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"3 Pipelines"},{"location":"3_pipelines/#3-pipelines","text":"In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"3 Pipelines"},{"location":"3_refresh/","text":"3 Refresh The refresh button allows users to reload the file structure information within the currently added folders.","title":"3 Refresh"},{"location":"3_refresh/#3-refresh","text":"The refresh button allows users to reload the file structure information within the currently added folders.","title":"3 Refresh"},{"location":"3_view_control_panel/","text":"3 View Control Panel Situated in the lower right corner, this section manages display settings and visualization options.","title":"3 View Control Panel"},{"location":"3_view_control_panel/#3-view-control-panel","text":"Situated in the lower right corner, this section manages display settings and visualization options.","title":"3 View Control Panel"},{"location":"4_attachments/","text":"4 Attachments In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"4 Attachments"},{"location":"4_attachments/#4-attachments","text":"In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"4 Attachments"},{"location":"4_dataset_browing_page/","text":"4 Dataset Browing Page The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4 Dataset Browing Page"},{"location":"4_dataset_browing_page/#4-dataset-browing-page","text":"The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4 Dataset Browing Page"},{"location":"4_manually_split/","text":"4 Manually Split To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"4 Manually Split"},{"location":"4_manually_split/#4-manually-split","text":"To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"4 Manually Split"},{"location":"4_smooth_processing_pipeline_auto/","text":"4 Smooth Processing Pipeline (Auto) The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"4 Smooth Processing Pipeline (Auto)"},{"location":"4_smooth_processing_pipeline_auto/#4-smooth-processing-pipeline-auto","text":"The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"4 Smooth Processing Pipeline (Auto)"},{"location":"4_software_page_overview/","text":"4 Software Page Overview 4.1 Welcome Page Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages. 4.2 Dataset Parse Page The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs. 4.3 Dataset Detail Page The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews. 4.4 Dataset Browing Page The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data. 4.5 Pipelines Page The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4 Software Page Overview"},{"location":"4_software_page_overview/#4-software-page-overview","text":"","title":"4 Software Page Overview"},{"location":"4_software_page_overview/#41-welcome-page","text":"Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"4.1 Welcome Page"},{"location":"4_software_page_overview/#42-dataset-parse-page","text":"The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"4.2 Dataset Parse Page"},{"location":"4_software_page_overview/#43-dataset-detail-page","text":"The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"4.3 Dataset Detail Page"},{"location":"4_software_page_overview/#44-dataset-browing-page","text":"The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4.4 Dataset Browing Page"},{"location":"4_software_page_overview/#45-pipelines-page","text":"The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4.5 Pipelines Page"},{"location":"5_automatic_split/","text":"5 Automatic Split For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"5 Automatic Split"},{"location":"5_automatic_split/#5-automatic-split","text":"For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"5 Automatic Split"},{"location":"5_mpf_phase_map_calculation_pipeline_auto/","text":"5 MPF Phase Map Calculation Pipeline (Auto) The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"5_mpf_phase_map_calculation_pipeline_auto/#5-mpf-phase-map-calculation-pipeline-auto","text":"The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"5_pipelines_page/","text":"5 Pipelines Page The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"5 Pipelines Page"},{"location":"5_pipelines_page/#5-pipelines-page","text":"The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"5 Pipelines Page"},{"location":"5_table_setting_%26_filters/","text":"5 Table setting & Filters The table can display multiple annotation information and users can also filter data through filters.","title":"5 Table setting &amp; Filters"},{"location":"5_table_setting_%26_filters/#5-table-setting-filters","text":"The table can display multiple annotation information and users can also filter data through filters.","title":"5 Table setting &amp; Filters"},{"location":"5_welcome_page_/","text":"5 Welcome Page 5.1 New Dataset To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset. 5.2 Recent Dataset If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5 Welcome Page"},{"location":"5_welcome_page_/#5-welcome-page","text":"","title":"5 Welcome Page"},{"location":"5_welcome_page_/#51-new-dataset","text":"To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"5.1 New Dataset"},{"location":"5_welcome_page_/#52-recent-dataset","text":"If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5.2 Recent Dataset"},{"location":"6_broom/","text":"6 Broom Clicking the broom icon will hide the white dividing line.","title":"6 Broom"},{"location":"6_broom/#6-broom","text":"Clicking the broom icon will hide the white dividing line.","title":"6 Broom"},{"location":"6_dataset_parse_page_/","text":"6 Dataset Parse Page 6.1 Add Folder After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path. 6.2 Prepare Dataset After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders. 6.3 Refresh The refresh button allows users to reload the file structure information within the currently added folders. 6.4 Manually Split To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button. 6.5 Automatic Split For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button. 6.6 Broom Clicking the broom icon will hide the white dividing line. 6.7 Parse Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\". 6.8 Data swapper After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it. 6.8.1 Query Data Users can query the data by setting different search criteria to retrieve specific information from the dataset. 6.8.2 Move Data For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects. 6.9 Settings On the Settings page, users can perform data export and deletion. 6.9.1 Export The Export button provides various export options for users to choose export format. 6.9.2 Delete The delete button provides an additional verification step to prevent accidental deletions.","title":"6 Dataset Parse Page"},{"location":"6_dataset_parse_page_/#6-dataset-parse-page","text":"","title":"6 Dataset Parse Page"},{"location":"6_dataset_parse_page_/#61-add-folder","text":"After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"6.1 Add Folder"},{"location":"6_dataset_parse_page_/#62-prepare-dataset","text":"After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"6.2 Prepare Dataset"},{"location":"6_dataset_parse_page_/#63-refresh","text":"The refresh button allows users to reload the file structure information within the currently added folders.","title":"6.3 Refresh"},{"location":"6_dataset_parse_page_/#64-manually-split","text":"To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.4 Manually Split"},{"location":"6_dataset_parse_page_/#65-automatic-split","text":"For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.5 Automatic Split"},{"location":"6_dataset_parse_page_/#66-broom","text":"Clicking the broom icon will hide the white dividing line.","title":"6.6 Broom"},{"location":"6_dataset_parse_page_/#67-parse","text":"Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"6.7 Parse"},{"location":"6_dataset_parse_page_/#68-data-swapper","text":"After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it.","title":"6.8 Data swapper"},{"location":"6_dataset_parse_page_/#681-query-data","text":"Users can query the data by setting different search criteria to retrieve specific information from the dataset.","title":"6.8.1 Query Data"},{"location":"6_dataset_parse_page_/#682-move-data","text":"For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"6.8.2 Move Data"},{"location":"6_dataset_parse_page_/#69-settings","text":"On the Settings page, users can perform data export and deletion.","title":"6.9 Settings"},{"location":"6_dataset_parse_page_/#691-export","text":"The Export button provides various export options for users to choose export format.","title":"6.9.1 Export"},{"location":"6_dataset_parse_page_/#692-delete","text":"The delete button provides an additional verification step to prevent accidental deletions.","title":"6.9.2 Delete"},{"location":"6_rmpfsl_map_calculation_pipeline_auto/","text":"6 RMPFSL Map Calculation Pipeline (Auto) The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"6_rmpfsl_map_calculation_pipeline_auto/#6-rmpfsl-map-calculation-pipeline-auto","text":"The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"7_dataset_detail_page/","text":"7 Dataset Detail Page The Dataset Detail Page displays the data details within the dataset and provides users with the functionality to annotate the data. 7.1 Reports In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data. 7.2 Labels In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it. 7.3 Pipelines In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results 7.4 Attachments In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen. 7.5 Table setting & Filters The table can display multiple annotation information and users can also filter data through filters.","title":"7 Dataset Detail Page"},{"location":"7_dataset_detail_page/#7-dataset-detail-page","text":"The Dataset Detail Page displays the data details within the dataset and provides users with the functionality to annotate the data.","title":"7 Dataset Detail Page"},{"location":"7_dataset_detail_page/#71-reports","text":"In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"7.1 Reports"},{"location":"7_dataset_detail_page/#72-labels","text":"In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"7.2 Labels"},{"location":"7_dataset_detail_page/#73-pipelines","text":"In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"7.3 Pipelines"},{"location":"7_dataset_detail_page/#74-attachments","text":"In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"7.4 Attachments"},{"location":"7_dataset_detail_page/#75-table-setting-filters","text":"The table can display multiple annotation information and users can also filter data through filters.","title":"7.5 Table setting &amp; Filters"},{"location":"7_mpf_map_calculation_pipeline_auto/","text":"7 MPF Map Calculation Pipeline (Auto) The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"7 MPF Map Calculation Pipeline (Auto)"},{"location":"7_mpf_map_calculation_pipeline_auto/#7-mpf-map-calculation-pipeline-auto","text":"The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"7 MPF Map Calculation Pipeline (Auto)"},{"location":"7_parse/","text":"7 Parse Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"7 Parse"},{"location":"7_parse/#7-parse","text":"Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"7 Parse"},{"location":"8.1_query_data/","text":"8.1 Query Data Users can query the data by setting different search criteria to retrieve specific information from the dataset.","title":"8.1 Query Data"},{"location":"8.1_query_data/#81-query-data","text":"Users can query the data by setting different search criteria to retrieve specific information from the dataset.","title":"8.1 Query Data"},{"location":"8.2_move_data/","text":"8.2 Move Data For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"8.2 Move Data"},{"location":"8.2_move_data/#82-move-data","text":"For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"8.2 Move Data"},{"location":"8_data_swapper/","text":"8 Data swapper After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it.","title":"8 Data swapper"},{"location":"8_data_swapper/#8-data-swapper","text":"After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it.","title":"8 Data swapper"},{"location":"8_dataset_browing_page/","text":"8 Dataset Browing Page The Dataset Browsing Page offers an browsing and interactive interface where users can visualize and render image data. 8.1 Image Interface 8.1.1 Reset Camera Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings. 8.1.2 Data Info In the top right corner of the image interface, there is an icon that can display basic information about the image. 8.2 Data Interaction & Toolbar 8.2.1 Interaction Info List In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering. 8.2.2 Layout Selection On this page, users can select the layout interface and achieve 3D reconstruction. 8.2.3 Window/Level (Contrast) This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width. 8.2.4 Pan To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view. 8.2.5 Zoom To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out. 8.2.6 Crosshair To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position. 8.2.7 Paint (Segmentation) In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image. 8.2.8 Rectangle (Measurement) In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI. 8.2.9 Polygon (Measurement) Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area. 8.2.10 Ruler (Measurement) Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points. 8.2.11 3D Crop Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8 Dataset Browing Page"},{"location":"8_dataset_browing_page/#8-dataset-browing-page","text":"The Dataset Browsing Page offers an browsing and interactive interface where users can visualize and render image data.","title":"8 Dataset Browing Page"},{"location":"8_dataset_browing_page/#81-image-interface","text":"","title":"8.1 Image Interface"},{"location":"8_dataset_browing_page/#811-reset-camera","text":"Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings.","title":"8.1.1 Reset Camera"},{"location":"8_dataset_browing_page/#812-data-info","text":"In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"8.1.2 Data Info"},{"location":"8_dataset_browing_page/#82-data-interaction-toolbar","text":"","title":"8.2 Data Interaction &amp; Toolbar"},{"location":"8_dataset_browing_page/#821-interaction-info-list","text":"In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering.","title":"8.2.1 Interaction Info List"},{"location":"8_dataset_browing_page/#822-layout-selection","text":"On this page, users can select the layout interface and achieve 3D reconstruction.","title":"8.2.2 Layout Selection"},{"location":"8_dataset_browing_page/#823-windowlevel-contrast","text":"This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width.","title":"8.2.3 Window/Level (Contrast)"},{"location":"8_dataset_browing_page/#824-pan","text":"To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view.","title":"8.2.4 Pan"},{"location":"8_dataset_browing_page/#825-zoom","text":"To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out.","title":"8.2.5 Zoom"},{"location":"8_dataset_browing_page/#826-crosshair","text":"To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position.","title":"8.2.6 Crosshair"},{"location":"8_dataset_browing_page/#827-paint-segmentation","text":"In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image.","title":"8.2.7 Paint (Segmentation)"},{"location":"8_dataset_browing_page/#828-rectangle-measurement","text":"In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI.","title":"8.2.8 Rectangle (Measurement)"},{"location":"8_dataset_browing_page/#829-polygon-measurement","text":"Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area.","title":"8.2.9 Polygon (Measurement)"},{"location":"8_dataset_browing_page/#8210-ruler-measurement","text":"Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points.","title":"8.2.10 Ruler (Measurement)"},{"location":"8_dataset_browing_page/#8211-3d-crop","text":"Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8.2.11 3D Crop"},{"location":"9.1_export/","text":"9.1 Export The Export button provides various export options for users to choose export format.","title":"9.1 Export"},{"location":"9.1_export/#91-export","text":"The Export button provides various export options for users to choose export format.","title":"9.1 Export"},{"location":"9.2_delete/","text":"9.2 Delete The delete button provides an additional verification step to prevent accidental deletions.","title":"9.2 Delete"},{"location":"9.2_delete/#92-delete","text":"The delete button provides an additional verification step to prevent accidental deletions.","title":"9.2 Delete"},{"location":"9_plugin_page_/","text":"9 Plugin Page Each pipeline consists of multiple nodes, which come in various types, each serving different functions. Plugins serve as nodes used to implement data processing algorithms. 9.1 Node 9.1.1 Varieties of Nodes The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file. 9.1.2 Add Node Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow. 9.2.2 Node Setting Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings. 9.2.1 Node status description The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management. 9.2 Plugin To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9 Plugin Page"},{"location":"9_plugin_page_/#9-plugin-page","text":"Each pipeline consists of multiple nodes, which come in various types, each serving different functions. Plugins serve as nodes used to implement data processing algorithms.","title":"9 Plugin Page"},{"location":"9_plugin_page_/#91-node","text":"","title":"9.1 Node"},{"location":"9_plugin_page_/#911-varieties-of-nodes","text":"The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file.","title":"9.1.1 Varieties of Nodes"},{"location":"9_plugin_page_/#912-add-node","text":"Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow.","title":"9.1.2 Add Node"},{"location":"9_plugin_page_/#922-node-setting","text":"Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings.","title":"9.2.2 Node Setting"},{"location":"9_plugin_page_/#921-node-status-description","text":"The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"9.2.1 Node status description"},{"location":"9_plugin_page_/#92-plugin","text":"To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9.2 Plugin"},{"location":"9_settings/","text":"9 Settings On the Settings page, users can perform data export and deletion.","title":"9 Settings"},{"location":"9_settings/#9-settings","text":"On the Settings page, users can perform data export and deletion.","title":"9 Settings"},{"location":"dataset_browing_page/","text":"Dataset Browing Page The Dataset Browsing Page offers an browsing and interactive interface where users can visualize and render image data.","title":"Dataset Browing Page"},{"location":"dataset_browing_page/#dataset-browing-page","text":"The Dataset Browsing Page offers an browsing and interactive interface where users can visualize and render image data.","title":"Dataset Browing Page"},{"location":"dataset_detail_page/","text":"Dataset Detail Page The Dataset Detail Page displays the data details within the dataset and provides users with the functionality to annotate the data.","title":"Dataset Detail Page"},{"location":"dataset_detail_page/#dataset-detail-page","text":"The Dataset Detail Page displays the data details within the dataset and provides users with the functionality to annotate the data.","title":"Dataset Detail Page"},{"location":"dataset_parse_page/","text":"Dataset Parse Page","title":"Dataset Parse Page"},{"location":"dataset_parse_page/#dataset-parse-page","text":"","title":"Dataset Parse Page"},{"location":"installation_and_setup/","text":"Installation and Setup","title":"Installation and Setup"},{"location":"installation_and_setup/#installation-and-setup","text":"","title":"Installation and Setup"},{"location":"introduction/","text":"Introduction Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"Introduction"},{"location":"introduction/#introduction","text":"Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"Introduction"},{"location":"pipelines_page_mpf_post-processing/","text":"Pipelines Page (MPF Post-processing) The MPF post-processing pipeline module offers users a versatile and flexible tool for customizing and executing data processing workflows through pipeline configuration and data management. Currently, this module is primarily utilized for MPF post-processing, providing multiple pipelines tailored for specific post-processing of MPF data. The plugin module allows users to design and upload their own data processing algorithms as plugins to meet specific standards. Users can integrate these plugins, each with unique functionalities, into coherent pipelines within the platform. This enables users to process data individually or in batch mode while maintaining supervision over the derivatives and results generated during the processing operations.","title":"Pipelines Page (MPF Post-processing)"},{"location":"pipelines_page_mpf_post-processing/#pipelines-page-mpf-post-processing","text":"The MPF post-processing pipeline module offers users a versatile and flexible tool for customizing and executing data processing workflows through pipeline configuration and data management. Currently, this module is primarily utilized for MPF post-processing, providing multiple pipelines tailored for specific post-processing of MPF data. The plugin module allows users to design and upload their own data processing algorithms as plugins to meet specific standards. Users can integrate these plugins, each with unique functionalities, into coherent pipelines within the platform. This enables users to process data individually or in batch mode while maintaining supervision over the derivatives and results generated during the processing operations.","title":"Pipelines Page (MPF Post-processing)"},{"location":"plugin_page/","text":"Plugin Page Each pipeline consists of multiple nodes, which come in various types, each serving different functions. Plugins serve as nodes used to implement data processing algorithms.","title":"Plugin Page"},{"location":"plugin_page/#plugin-page","text":"Each pipeline consists of multiple nodes, which come in various types, each serving different functions. Plugins serve as nodes used to implement data processing algorithms.","title":"Plugin Page"},{"location":"section1/","text":"1 Introduction Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"1 Introduction"},{"location":"section1/#1-introduction","text":"Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"1 Introduction"},{"location":"section10/","text":"10 Pipelines Page (MPF Post-processing) The MPF post-processing pipeline module offers users a versatile and flexible tool for customizing and executing data processing workflows through pipeline configuration and data management. Currently, this module is primarily utilized for MPF post-processing, providing multiple pipelines tailored for specific post-processing of MPF data. The plugin module allows users to design and upload their own data processing algorithms as plugins to meet specific standards. Users can integrate these plugins, each with unique functionalities, into coherent pipelines within the platform. This enables users to process data individually or in batch mode while maintaining supervision over the derivatives and results generated during the processing operations. 10.1 New Pipeline In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration. 10.2 Pipeline Control Panel Located at the bottom of the interface, this section provides pipeline execution controls and management functions. 10.2.1 Execute Pipeline 10.2.2 Rename Pipeline 10.2.3 Save Change 10.2.4 Export Pipeline 10.3 View Control Panel Situated in the lower right corner, this section manages display settings and visualization options. 10.3.1 Zoom In / Out 10.3.2 Fit View 10.3.3 Select Mode 10.3.4 Toggle Link Visibility 10.4 Smooth Processing Pipeline (Auto) The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node. 10.5 MPF Phase Map Calculation Pipeline (Auto) The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask. 10.6 RMPFSL Map Calculation Pipeline (Auto) The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps. 10.7 MPF Map Calculation Pipeline (Auto) The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10 Pipelines Page (MPF Post-processing)"},{"location":"section10/#10-pipelines-page-mpf-post-processing","text":"The MPF post-processing pipeline module offers users a versatile and flexible tool for customizing and executing data processing workflows through pipeline configuration and data management. Currently, this module is primarily utilized for MPF post-processing, providing multiple pipelines tailored for specific post-processing of MPF data. The plugin module allows users to design and upload their own data processing algorithms as plugins to meet specific standards. Users can integrate these plugins, each with unique functionalities, into coherent pipelines within the platform. This enables users to process data individually or in batch mode while maintaining supervision over the derivatives and results generated during the processing operations.","title":"10 Pipelines Page (MPF Post-processing)"},{"location":"section10/#101-new-pipeline","text":"In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"10.1 New Pipeline"},{"location":"section10/#102-pipeline-control-panel","text":"Located at the bottom of the interface, this section provides pipeline execution controls and management functions.","title":"10.2 Pipeline Control Panel"},{"location":"section10/#1021-execute-pipeline","text":"","title":"10.2.1 Execute Pipeline"},{"location":"section10/#1022-rename-pipeline","text":"","title":"10.2.2 Rename Pipeline"},{"location":"section10/#1023-save-change","text":"","title":"10.2.3 Save Change"},{"location":"section10/#1024-export-pipeline","text":"","title":"10.2.4 Export Pipeline"},{"location":"section10/#103-view-control-panel","text":"Situated in the lower right corner, this section manages display settings and visualization options.","title":"10.3 View Control Panel"},{"location":"section10/#1031-zoom-in-out","text":"","title":"10.3.1 Zoom In / Out"},{"location":"section10/#1032-fit-view","text":"","title":"10.3.2 Fit View"},{"location":"section10/#1033-select-mode","text":"","title":"10.3.3 Select Mode"},{"location":"section10/#1034-toggle-link-visibility","text":"","title":"10.3.4 Toggle Link Visibility"},{"location":"section10/#104-smooth-processing-pipeline-auto","text":"The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"10.4 Smooth Processing Pipeline (Auto)"},{"location":"section10/#105-mpf-phase-map-calculation-pipeline-auto","text":"The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"10.5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"section10/#106-rmpfsl-map-calculation-pipeline-auto","text":"The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"10.6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"section10/#107-mpf-map-calculation-pipeline-auto","text":"The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10.7 MPF Map Calculation Pipeline (Auto)"},{"location":"section2/","text":"2 Software Description Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"2 Software Description"},{"location":"section2/#2-software-description","text":"Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"2 Software Description"},{"location":"section3/","text":"3 Installation and Setup 3.1 Download PMTaro installer & Run setup wizard Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed! 3.2 Configuration Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3 Installation and Setup"},{"location":"section3/#3-installation-and-setup","text":"","title":"3 Installation and Setup"},{"location":"section3/#31-download-pmtaro-installer-run-setup-wizard","text":"Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"3.1 Download PMTaro installer &amp; Run setup wizard"},{"location":"section3/#32-configuration","text":"Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3.2 Configuration"},{"location":"section4/","text":"4 Software Page Overview 4.1 Welcome Page Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages. 4.2 Dataset Parse Page The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs. 4.3 Dataset Detail Page The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews. 4.4 Dataset Browing Page The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data. 4.5 Pipelines Page The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4 Software Page Overview"},{"location":"section4/#4-software-page-overview","text":"","title":"4 Software Page Overview"},{"location":"section4/#41-welcome-page","text":"Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"4.1 Welcome Page"},{"location":"section4/#42-dataset-parse-page","text":"The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"4.2 Dataset Parse Page"},{"location":"section4/#43-dataset-detail-page","text":"The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"4.3 Dataset Detail Page"},{"location":"section4/#44-dataset-browing-page","text":"The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4.4 Dataset Browing Page"},{"location":"section4/#45-pipelines-page","text":"The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4.5 Pipelines Page"},{"location":"section5/","text":"5 Welcome Page 5.1 New Dataset To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset. 5.2 Recent Dataset If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5 Welcome Page"},{"location":"section5/#5-welcome-page","text":"","title":"5 Welcome Page"},{"location":"section5/#51-new-dataset","text":"To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"5.1 New Dataset"},{"location":"section5/#52-recent-dataset","text":"If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5.2 Recent Dataset"},{"location":"section6/","text":"6 Dataset Parse Page 6.1 Add Folder After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path. 6.2 Prepare Dataset After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders. 6.3 Refresh The refresh button allows users to reload the file structure information within the currently added folders. 6.4 Manually Split To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button. 6.5 Automatic Split For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button. 6.6 Broom Clicking the broom icon will hide the white dividing line. 6.7 Parse Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\". 6.8 Data swapper After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it. 6.8.1 Query Data Users can query the data by setting different search criteria to retrieve specific information from the dataset. 6.8.2 Move Data For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects. 6.9 Settings On the Settings page, users can perform data export and deletion. 6.9.1 Export The Export button provides various export options for users to choose export format. 6.9.2 Delete The delete button provides an additional verification step to prevent accidental deletions.","title":"6 Dataset Parse Page"},{"location":"section6/#6-dataset-parse-page","text":"","title":"6 Dataset Parse Page"},{"location":"section6/#61-add-folder","text":"After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"6.1 Add Folder"},{"location":"section6/#62-prepare-dataset","text":"After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"6.2 Prepare Dataset"},{"location":"section6/#63-refresh","text":"The refresh button allows users to reload the file structure information within the currently added folders.","title":"6.3 Refresh"},{"location":"section6/#64-manually-split","text":"To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.4 Manually Split"},{"location":"section6/#65-automatic-split","text":"For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.5 Automatic Split"},{"location":"section6/#66-broom","text":"Clicking the broom icon will hide the white dividing line.","title":"6.6 Broom"},{"location":"section6/#67-parse","text":"Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"6.7 Parse"},{"location":"section6/#68-data-swapper","text":"After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it.","title":"6.8 Data swapper"},{"location":"section6/#681-query-data","text":"Users can query the data by setting different search criteria to retrieve specific information from the dataset.","title":"6.8.1 Query Data"},{"location":"section6/#682-move-data","text":"For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"6.8.2 Move Data"},{"location":"section6/#69-settings","text":"On the Settings page, users can perform data export and deletion.","title":"6.9 Settings"},{"location":"section6/#691-export","text":"The Export button provides various export options for users to choose export format.","title":"6.9.1 Export"},{"location":"section6/#692-delete","text":"The delete button provides an additional verification step to prevent accidental deletions.","title":"6.9.2 Delete"},{"location":"section7/","text":"7 Dataset Detail Page The Dataset Detail Page displays the data details within the dataset and provides users with the functionality to annotate the data. 7.1 Reports In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data. 7.2 Labels In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it. 7.3 Pipelines In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results 7.4 Attachments In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen. 7.5 Table setting & Filters The table can display multiple annotation information and users can also filter data through filters.","title":"7 Dataset Detail Page"},{"location":"section7/#7-dataset-detail-page","text":"The Dataset Detail Page displays the data details within the dataset and provides users with the functionality to annotate the data.","title":"7 Dataset Detail Page"},{"location":"section7/#71-reports","text":"In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"7.1 Reports"},{"location":"section7/#72-labels","text":"In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"7.2 Labels"},{"location":"section7/#73-pipelines","text":"In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"7.3 Pipelines"},{"location":"section7/#74-attachments","text":"In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"7.4 Attachments"},{"location":"section7/#75-table-setting-filters","text":"The table can display multiple annotation information and users can also filter data through filters.","title":"7.5 Table setting &amp; Filters"},{"location":"section8/","text":"8 Dataset Browing Page The Dataset Browsing Page offers an browsing and interactive interface where users can visualize and render image data. 8.1 Image Interface 8.1.1 Reset Camera Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings. 8.1.2 Data Info In the top right corner of the image interface, there is an icon that can display basic information about the image. 8.2 Data Interaction & Toolbar 8.2.1 Interaction Info List In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering. 8.2.2 Layout Selection On this page, users can select the layout interface and achieve 3D reconstruction. 8.2.3 Window/Level (Contrast) This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width. 8.2.4 Pan To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view. 8.2.5 Zoom To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out. 8.2.6 Crosshair To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position. 8.2.7 Paint (Segmentation) In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image. 8.2.8 Rectangle (Measurement) In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI. 8.2.9 Polygon (Measurement) Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area. 8.2.10 Ruler (Measurement) Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points. 8.2.11 3D Crop Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8 Dataset Browing Page"},{"location":"section8/#8-dataset-browing-page","text":"The Dataset Browsing Page offers an browsing and interactive interface where users can visualize and render image data.","title":"8 Dataset Browing Page"},{"location":"section8/#81-image-interface","text":"","title":"8.1 Image Interface"},{"location":"section8/#811-reset-camera","text":"Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings.","title":"8.1.1 Reset Camera"},{"location":"section8/#812-data-info","text":"In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"8.1.2 Data Info"},{"location":"section8/#82-data-interaction-toolbar","text":"","title":"8.2 Data Interaction &amp; Toolbar"},{"location":"section8/#821-interaction-info-list","text":"In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering.","title":"8.2.1 Interaction Info List"},{"location":"section8/#822-layout-selection","text":"On this page, users can select the layout interface and achieve 3D reconstruction.","title":"8.2.2 Layout Selection"},{"location":"section8/#823-windowlevel-contrast","text":"This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width.","title":"8.2.3 Window/Level (Contrast)"},{"location":"section8/#824-pan","text":"To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view.","title":"8.2.4 Pan"},{"location":"section8/#825-zoom","text":"To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out.","title":"8.2.5 Zoom"},{"location":"section8/#826-crosshair","text":"To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position.","title":"8.2.6 Crosshair"},{"location":"section8/#827-paint-segmentation","text":"In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image.","title":"8.2.7 Paint (Segmentation)"},{"location":"section8/#828-rectangle-measurement","text":"In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI.","title":"8.2.8 Rectangle (Measurement)"},{"location":"section8/#829-polygon-measurement","text":"Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area.","title":"8.2.9 Polygon (Measurement)"},{"location":"section8/#8210-ruler-measurement","text":"Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points.","title":"8.2.10 Ruler (Measurement)"},{"location":"section8/#8211-3d-crop","text":"Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8.2.11 3D Crop"},{"location":"section9/","text":"9 Plugin Page Each pipeline consists of multiple nodes, which come in various types, each serving different functions. Plugins serve as nodes used to implement data processing algorithms. 9.1 Node 9.1.1 Varieties of Nodes The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file. 9.1.2 Add Node Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow. 9.2.2 Node Setting Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings. 9.2.1 Node status description The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management. 9.2 Plugin To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9 Plugin Page"},{"location":"section9/#9-plugin-page","text":"Each pipeline consists of multiple nodes, which come in various types, each serving different functions. Plugins serve as nodes used to implement data processing algorithms.","title":"9 Plugin Page"},{"location":"section9/#91-node","text":"","title":"9.1 Node"},{"location":"section9/#911-varieties-of-nodes","text":"The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file.","title":"9.1.1 Varieties of Nodes"},{"location":"section9/#912-add-node","text":"Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow.","title":"9.1.2 Add Node"},{"location":"section9/#922-node-setting","text":"Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings.","title":"9.2.2 Node Setting"},{"location":"section9/#921-node-status-description","text":"The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"9.2.1 Node status description"},{"location":"section9/#92-plugin","text":"To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9.2 Plugin"},{"location":"software_description/","text":"Software Description Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"Software Description"},{"location":"software_description/#software-description","text":"Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"Software Description"},{"location":"software_page_overview/","text":"Software Page Overview","title":"Software Page Overview"},{"location":"software_page_overview/#software-page-overview","text":"","title":"Software Page Overview"},{"location":"welcome_page/","text":"Welcome Page","title":"Welcome Page"},{"location":"welcome_page/#welcome-page","text":"","title":"Welcome Page"},{"location":"chapter_10/10_1_new_pipeline/","text":"10.1 New Pipeline In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"10.1 New Pipeline"},{"location":"chapter_10/10_1_new_pipeline/#101-new-pipeline","text":"In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"10.1 New Pipeline"},{"location":"chapter_10/10_2_pipeline_control_panel/","text":"10.2 Pipeline Control Panel Located at the bottom of the interface, this section provides pipeline execution controls and management functions. 10.2.1 Execute Pipeline 10.2.2 Rename Pipeline 10.2.3 Save Change 10.2.4 Export Pipeline","title":"10.2 Pipeline Control Panel"},{"location":"chapter_10/10_2_pipeline_control_panel/#102-pipeline-control-panel","text":"Located at the bottom of the interface, this section provides pipeline execution controls and management functions.","title":"10.2 Pipeline Control Panel"},{"location":"chapter_10/10_2_pipeline_control_panel/#1021-execute-pipeline","text":"","title":"10.2.1 Execute Pipeline"},{"location":"chapter_10/10_2_pipeline_control_panel/#1022-rename-pipeline","text":"","title":"10.2.2 Rename Pipeline"},{"location":"chapter_10/10_2_pipeline_control_panel/#1023-save-change","text":"","title":"10.2.3 Save Change"},{"location":"chapter_10/10_2_pipeline_control_panel/#1024-export-pipeline","text":"","title":"10.2.4 Export Pipeline"},{"location":"chapter_10/10_3_view_control_panel/","text":"10.3 View Control Panel Situated in the lower right corner, this section manages display settings and visualization options. 10.3.1 Zoom In / Out 10.3.2 Fit View 10.3.3 Select Mode 10.3.4 Toggle Link Visibility 10.4 Smooth Processing Pipeline (Auto) The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"10.3 View Control Panel"},{"location":"chapter_10/10_3_view_control_panel/#103-view-control-panel","text":"Situated in the lower right corner, this section manages display settings and visualization options.","title":"10.3 View Control Panel"},{"location":"chapter_10/10_3_view_control_panel/#1031-zoom-in-out","text":"","title":"10.3.1 Zoom In / Out"},{"location":"chapter_10/10_3_view_control_panel/#1032-fit-view","text":"","title":"10.3.2 Fit View"},{"location":"chapter_10/10_3_view_control_panel/#1033-select-mode","text":"","title":"10.3.3 Select Mode"},{"location":"chapter_10/10_3_view_control_panel/#1034-toggle-link-visibility","text":"","title":"10.3.4 Toggle Link Visibility"},{"location":"chapter_10/10_3_view_control_panel/#104-smooth-processing-pipeline-auto","text":"The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"10.4 Smooth Processing Pipeline (Auto)"},{"location":"chapter_10/10_5_mpf_phase_map_calculation_pipeline_auto/","text":"10.5 MPF Phase Map Calculation Pipeline (Auto) The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"10.5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"chapter_10/10_5_mpf_phase_map_calculation_pipeline_auto/#105-mpf-phase-map-calculation-pipeline-auto","text":"The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"10.5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"chapter_10/10_6_rmpfsl_map_calculation_pipeline_auto/","text":"10.6 RMPFSL Map Calculation Pipeline (Auto) The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"10.6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"chapter_10/10_6_rmpfsl_map_calculation_pipeline_auto/#106-rmpfsl-map-calculation-pipeline-auto","text":"The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"10.6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"chapter_10/10_7_mpf_map_calculation_pipeline_auto/","text":"10.7 MPF Map Calculation Pipeline (Auto) The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10.7 MPF Map Calculation Pipeline (Auto)"},{"location":"chapter_10/10_7_mpf_map_calculation_pipeline_auto/#107-mpf-map-calculation-pipeline-auto","text":"The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10.7 MPF Map Calculation Pipeline (Auto)"},{"location":"chapter_3/3_1_download_pmtaro_installer_%26_run_setup_wizard/","text":"3.1 Download PMTaro installer & Run setup wizard Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"3.1 Download PMTaro installer &amp; Run setup wizard"},{"location":"chapter_3/3_1_download_pmtaro_installer_%26_run_setup_wizard/#31-download-pmtaro-installer-run-setup-wizard","text":"Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"3.1 Download PMTaro installer &amp; Run setup wizard"},{"location":"chapter_3/3_2_configuration/","text":"3.2 Configuration Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3.2 Configuration"},{"location":"chapter_3/3_2_configuration/#32-configuration","text":"Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3.2 Configuration"},{"location":"chapter_4/4_1_welcome_page/","text":"4.1 Welcome Page Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"4.1 Welcome Page"},{"location":"chapter_4/4_1_welcome_page/#41-welcome-page","text":"Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"4.1 Welcome Page"},{"location":"chapter_4/4_2_dataset_parse_page/","text":"4.2 Dataset Parse Page The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"4.2 Dataset Parse Page"},{"location":"chapter_4/4_2_dataset_parse_page/#42-dataset-parse-page","text":"The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"4.2 Dataset Parse Page"},{"location":"chapter_4/4_3_dataset_detail_page/","text":"4.3 Dataset Detail Page The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"4.3 Dataset Detail Page"},{"location":"chapter_4/4_3_dataset_detail_page/#43-dataset-detail-page","text":"The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"4.3 Dataset Detail Page"},{"location":"chapter_4/4_4_dataset_browing_page/","text":"4.4 Dataset Browing Page The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4.4 Dataset Browing Page"},{"location":"chapter_4/4_4_dataset_browing_page/#44-dataset-browing-page","text":"The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4.4 Dataset Browing Page"},{"location":"chapter_4/4_5_pipelines_page/","text":"4.5 Pipelines Page The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4.5 Pipelines Page"},{"location":"chapter_4/4_5_pipelines_page/#45-pipelines-page","text":"The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4.5 Pipelines Page"},{"location":"chapter_5/5_1_new_dataset/","text":"5.1 New Dataset To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"5.1 New Dataset"},{"location":"chapter_5/5_1_new_dataset/#51-new-dataset","text":"To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"5.1 New Dataset"},{"location":"chapter_5/5_2_recent_dataset/","text":"5.2 Recent Dataset If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5.2 Recent Dataset"},{"location":"chapter_5/5_2_recent_dataset/#52-recent-dataset","text":"If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5.2 Recent Dataset"},{"location":"chapter_6/6_1_add_folder/","text":"6.1 Add Folder After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"6.1 Add Folder"},{"location":"chapter_6/6_1_add_folder/#61-add-folder","text":"After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"6.1 Add Folder"},{"location":"chapter_6/6_2_prepare_dataset/","text":"6.2 Prepare Dataset After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"6.2 Prepare Dataset"},{"location":"chapter_6/6_2_prepare_dataset/#62-prepare-dataset","text":"After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"6.2 Prepare Dataset"},{"location":"chapter_6/6_3_refresh/","text":"6.3 Refresh The refresh button allows users to reload the file structure information within the currently added folders.","title":"6.3 Refresh"},{"location":"chapter_6/6_3_refresh/#63-refresh","text":"The refresh button allows users to reload the file structure information within the currently added folders.","title":"6.3 Refresh"},{"location":"chapter_6/6_4_manually_split/","text":"6.4 Manually Split To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.4 Manually Split"},{"location":"chapter_6/6_4_manually_split/#64-manually-split","text":"To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.4 Manually Split"},{"location":"chapter_6/6_5_automatic_split/","text":"6.5 Automatic Split For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.5 Automatic Split"},{"location":"chapter_6/6_5_automatic_split/#65-automatic-split","text":"For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.5 Automatic Split"},{"location":"chapter_6/6_6_broom/","text":"6.6 Broom Clicking the broom icon will hide the white dividing line.","title":"6.6 Broom"},{"location":"chapter_6/6_6_broom/#66-broom","text":"Clicking the broom icon will hide the white dividing line.","title":"6.6 Broom"},{"location":"chapter_6/6_7_parse/","text":"6.7 Parse Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"6.7 Parse"},{"location":"chapter_6/6_7_parse/#67-parse","text":"Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"6.7 Parse"},{"location":"chapter_6/6_8_data_swapper/","text":"6.8 Data swapper After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it. 6.8.1 Query Data Users can query the data by setting different search criteria to retrieve specific information from the dataset. 6.8.2 Move Data For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"6.8 Data swapper"},{"location":"chapter_6/6_8_data_swapper/#68-data-swapper","text":"After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it.","title":"6.8 Data swapper"},{"location":"chapter_6/6_8_data_swapper/#681-query-data","text":"Users can query the data by setting different search criteria to retrieve specific information from the dataset.","title":"6.8.1 Query Data"},{"location":"chapter_6/6_8_data_swapper/#682-move-data","text":"For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"6.8.2 Move Data"},{"location":"chapter_6/6_9_settings/","text":"6.9 Settings On the Settings page, users can perform data export and deletion. 6.9.1 Export The Export button provides various export options for users to choose export format. 6.9.2 Delete The delete button provides an additional verification step to prevent accidental deletions.","title":"6.9 Settings"},{"location":"chapter_6/6_9_settings/#69-settings","text":"On the Settings page, users can perform data export and deletion.","title":"6.9 Settings"},{"location":"chapter_6/6_9_settings/#691-export","text":"The Export button provides various export options for users to choose export format.","title":"6.9.1 Export"},{"location":"chapter_6/6_9_settings/#692-delete","text":"The delete button provides an additional verification step to prevent accidental deletions.","title":"6.9.2 Delete"},{"location":"chapter_7/7_1_reports/","text":"7.1 Reports In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"7.1 Reports"},{"location":"chapter_7/7_1_reports/#71-reports","text":"In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"7.1 Reports"},{"location":"chapter_7/7_2_labels/","text":"7.2 Labels In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"7.2 Labels"},{"location":"chapter_7/7_2_labels/#72-labels","text":"In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"7.2 Labels"},{"location":"chapter_7/7_3_pipelines/","text":"7.3 Pipelines In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"7.3 Pipelines"},{"location":"chapter_7/7_3_pipelines/#73-pipelines","text":"In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"7.3 Pipelines"},{"location":"chapter_7/7_4_attachments/","text":"7.4 Attachments In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"7.4 Attachments"},{"location":"chapter_7/7_4_attachments/#74-attachments","text":"In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"7.4 Attachments"},{"location":"chapter_7/7_5_table_setting_%26_filters/","text":"7.5 Table setting & Filters The table can display multiple annotation information and users can also filter data through filters.","title":"7.5 Table setting &amp; Filters"},{"location":"chapter_7/7_5_table_setting_%26_filters/#75-table-setting-filters","text":"The table can display multiple annotation information and users can also filter data through filters.","title":"7.5 Table setting &amp; Filters"},{"location":"chapter_8/8_1_image_interface/","text":"8.1 Image Interface 8.1.1 Reset Camera Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings. 8.1.2 Data Info In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"8.1 Image Interface"},{"location":"chapter_8/8_1_image_interface/#81-image-interface","text":"","title":"8.1 Image Interface"},{"location":"chapter_8/8_1_image_interface/#811-reset-camera","text":"Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings.","title":"8.1.1 Reset Camera"},{"location":"chapter_8/8_1_image_interface/#812-data-info","text":"In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"8.1.2 Data Info"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/","text":"8.2 Data Interaction & Toolbar 8.2.1 Interaction Info List In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering. 8.2.2 Layout Selection On this page, users can select the layout interface and achieve 3D reconstruction. 8.2.3 Window/Level (Contrast) This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width. 8.2.4 Pan To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view. 8.2.5 Zoom To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out. 8.2.6 Crosshair To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position. 8.2.7 Paint (Segmentation) In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image. 8.2.8 Rectangle (Measurement) In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI. 8.2.9 Polygon (Measurement) Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area. 8.2.10 Ruler (Measurement) Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points. 8.2.11 3D Crop Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8.2 Data Interaction &amp; Toolbar"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#82-data-interaction-toolbar","text":"","title":"8.2 Data Interaction &amp; Toolbar"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#821-interaction-info-list","text":"In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering.","title":"8.2.1 Interaction Info List"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#822-layout-selection","text":"On this page, users can select the layout interface and achieve 3D reconstruction.","title":"8.2.2 Layout Selection"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#823-windowlevel-contrast","text":"This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width.","title":"8.2.3 Window/Level (Contrast)"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#824-pan","text":"To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view.","title":"8.2.4 Pan"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#825-zoom","text":"To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out.","title":"8.2.5 Zoom"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#826-crosshair","text":"To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position.","title":"8.2.6 Crosshair"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#827-paint-segmentation","text":"In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image.","title":"8.2.7 Paint (Segmentation)"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#828-rectangle-measurement","text":"In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI.","title":"8.2.8 Rectangle (Measurement)"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#829-polygon-measurement","text":"Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area.","title":"8.2.9 Polygon (Measurement)"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#8210-ruler-measurement","text":"Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points.","title":"8.2.10 Ruler (Measurement)"},{"location":"chapter_8/8_2_data_interaction_%26_toolbar/#8211-3d-crop","text":"Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8.2.11 3D Crop"},{"location":"chapter_9/9_1_node/","text":"9.1 Node 9.1.1 Varieties of Nodes The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file. 9.1.2 Add Node Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow. 9.2.2 Node Setting Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings. 9.2.1 Node status description The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"9.1 Node"},{"location":"chapter_9/9_1_node/#91-node","text":"","title":"9.1 Node"},{"location":"chapter_9/9_1_node/#911-varieties-of-nodes","text":"The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file.","title":"9.1.1 Varieties of Nodes"},{"location":"chapter_9/9_1_node/#912-add-node","text":"Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow.","title":"9.1.2 Add Node"},{"location":"chapter_9/9_1_node/#922-node-setting","text":"Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings.","title":"9.2.2 Node Setting"},{"location":"chapter_9/9_1_node/#921-node-status-description","text":"The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"9.2.1 Node status description"},{"location":"chapter_9/9_2_plugin_/","text":"9.2 Plugin To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9.2 Plugin"},{"location":"chapter_9/9_2_plugin_/#92-plugin","text":"To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9.2 Plugin"},{"location":"section1/","text":"1 Introduction Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"1 Introduction"},{"location":"section1/#1-introduction","text":"Developed by Illuminatio Medical Technologies (IMT), this software provides customized MPF data processing solutions. It includes multiple functions, covering data management, image browsing, ROI data annotation and MPF post-processing, and can realize the entire process of MPF data processing. Please read this manual carefully before using the software.","title":"1 Introduction"},{"location":"section10/","text":"10 Pipelines Page (MPF Post-processing) \u672c\u7ae0\u5185\u5bb9 New Pipeline Pipeline Control Panel View Control Panel MPF Phase Map Calculation Pipeline (Auto) RMPFSL Map Calculation Pipeline (Auto) MPF Map Calculation Pipeline (Auto)","title":"10 Pipelines Page (MPF Post-processing)"},{"location":"section10/#10-pipelines-page-mpf-post-processing","text":"","title":"10 Pipelines Page (MPF Post-processing)"},{"location":"section10/#_1","text":"New Pipeline Pipeline Control Panel View Control Panel MPF Phase Map Calculation Pipeline (Auto) RMPFSL Map Calculation Pipeline (Auto) MPF Map Calculation Pipeline (Auto)","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section10/subsection1/","text":"10.1 New Pipeline In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"New Pipeline"},{"location":"section10/subsection1/#101-new-pipeline","text":"In the Pipelines section, there is a \"New\" button at the bottom. Clicking this button will automatically direct users to the pipeline interface, where users can design custom pipelines according to their specific requirements. Each pipeline must contain an Input Node, but a pipeline consisting of only an Input Node is not valid. Once users have completed the pipeline design, click the Save button to preserve configuration.","title":"10.1 New Pipeline"},{"location":"section10/subsection2/","text":"10.2 Pipeline Control Panel Located at the bottom of the interface, this section provides pipeline execution controls and management functions. 10.2.1 Execute Pipeline 10.2.2 Rename Pipeline 10.2.3 Save Change 10.2.4 Export Pipeline","title":"Pipeline Control Panel"},{"location":"section10/subsection2/#102-pipeline-control-panel","text":"Located at the bottom of the interface, this section provides pipeline execution controls and management functions.","title":"10.2 Pipeline Control Panel"},{"location":"section10/subsection2/#1021-execute-pipeline","text":"","title":"10.2.1 Execute Pipeline"},{"location":"section10/subsection2/#1022-rename-pipeline","text":"","title":"10.2.2 Rename Pipeline"},{"location":"section10/subsection2/#1023-save-change","text":"","title":"10.2.3 Save Change"},{"location":"section10/subsection2/#1024-export-pipeline","text":"","title":"10.2.4 Export Pipeline"},{"location":"section10/subsection3/","text":"10.3 View Control Panel Situated in the lower right corner, this section manages display settings and visualization options. 10.3.1 Zoom In / Out 10.3.2 Fit View 10.3.3 Select Mode 10.3.4 Toggle Link Visibility 10.4 Smooth Processing Pipeline (Auto) The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"View Control Panel"},{"location":"section10/subsection3/#103-view-control-panel","text":"Situated in the lower right corner, this section manages display settings and visualization options.","title":"10.3 View Control Panel"},{"location":"section10/subsection3/#1031-zoom-in-out","text":"","title":"10.3.1 Zoom In / Out"},{"location":"section10/subsection3/#1032-fit-view","text":"","title":"10.3.2 Fit View"},{"location":"section10/subsection3/#1033-select-mode","text":"","title":"10.3.3 Select Mode"},{"location":"section10/subsection3/#1034-toggle-link-visibility","text":"","title":"10.3.4 Toggle Link Visibility"},{"location":"section10/subsection3/#104-smooth-processing-pipeline-auto","text":"The Smooth Processing Pipeline is an automated workflow composed of sequential processing nodes. Once the input parameters are configured, users can initiate the pipeline by clicking the Execute button, after which the backend will automatically execute all nodes in pipeline. Users can review the data by Preview node. Firstly, there are two methods available for adding data: Method 1: Data Drag-and-Drop from Project Interface In the project interface, locate the data you wish to process Click and hold the mouse button on the desired data Drag the selected data to the pipeline option at the top of the interface The system will automatically navigate to the pipeline interface Continue dragging the data to the corresponding node Release the mouse button to initiate automatic data loading Important Note: Ensure that the data type of your selected file matches the data type specified in the Input Node. Type mismatches will not be processed. The second method allows users to directly input the OID of the target data into the Input Node field within the pipeline interface. Method 2: Direct OID Input Simply enter the OID (Object Identifier) of the data users wish to process directly into the Input Node in the pipeline interface. Once the input data is properly configured, click the Execute button to initiate data processing. After the processing is complete, users can examine the results using the Preview Node.","title":"10.4 Smooth Processing Pipeline (Auto)"},{"location":"section10/subsection5/","text":"10.5 MPF Phase Map Calculation Pipeline (Auto) The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"MPF Phase Map Calculation Pipeline (Auto)"},{"location":"section10/subsection5/#105-mpf-phase-map-calculation-pipeline-auto","text":"The MPF Phase Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Phase Map and Phase Mask.","title":"10.5 MPF Phase Map Calculation Pipeline (Auto)"},{"location":"section10/subsection6/","text":"10.6 RMPFSL Map Calculation Pipeline (Auto) The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"RMPFSL Map Calculation Pipeline (Auto)"},{"location":"section10/subsection6/#106-rmpfsl-map-calculation-pipeline-auto","text":"The RMPFSL Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate RMPFSL Maps.","title":"10.6 RMPFSL Map Calculation Pipeline (Auto)"},{"location":"section10/subsection7/","text":"10.7 MPF Map Calculation Pipeline (Auto) The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"MPF Map Calculation Pipeline (Auto)"},{"location":"section10/subsection7/#107-mpf-map-calculation-pipeline-auto","text":"The MPF Map Calculation Pipeline is a dedicated workflow architecture optimized for MPF scan sequence analysis. The current computational framework is implemented to generate MPF Maps.","title":"10.7 MPF Map Calculation Pipeline (Auto)"},{"location":"section2/","text":"2 Software Description Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"2 Software Description"},{"location":"section2/#2-software-description","text":"Name: PMTaro Version: 1.0.0 Developer: PMTaro Team Intended Use: Medical image data management, medical image data browsing, medical image data annotation, MPF data post-processing Operating System: Windows 10/11, macOS 12+ Minimum RAM: 8GB Storage Space: 5GB Other Requirements: Python 3.8+ Orthanc 14+, PostgreSQL 13+","title":"2 Software Description"},{"location":"section3/","text":"3 Installation and Setup \u672c\u7ae0\u5185\u5bb9 Download PMTaro installer & Run setup wizard Configuration","title":"3 Installation and Setup"},{"location":"section3/#3-installation-and-setup","text":"","title":"3 Installation and Setup"},{"location":"section3/#_1","text":"Download PMTaro installer & Run setup wizard Configuration","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section3/subsection1/","text":"3.1 Download PMTaro installer & Run setup wizard Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"Download PMTaro installer & Run setup wizard"},{"location":"section3/subsection1/#31-download-pmtaro-installer-run-setup-wizard","text":"Step 1\uff1aLaunch the PMTaro installation package and click \"Next\" to proceed with the installation process. Step 2: Review the license agreement carefully. The software installation requires your acceptance of the terms and conditions stated in this agreement before proceeding. Once you have read and agreed to the terms, click \"Next\" to continue. Step 3: Select your preferred installation directory, ensuring sufficient disk space is available for the installation (minimum 500MB required). Click \"Next\" to proceed with the installation. Step 4: The default settings will create convenient quick-launch icons. Click \"Next\" to continue. Step 5: The installation is now ready to begin. For optimal performance and ease of access, we recommend maintaining the default configuration settings. Click \"Install\" to commence the installation process. Step 6: The software installation has been successfully completed!","title":"3.1 Download PMTaro installer &amp; Run setup wizard"},{"location":"section3/subsection2/","text":"3.2 Configuration Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"Configuration"},{"location":"section3/subsection2/#32-configuration","text":"Step 1: We will enter the software configuration stage, which is designated for configuring the software's database and operational environment. Please click \"Next\" at this point to proceed. Step 2: Then, we will select the necessary components for installation. All of these components must be installed for the software correctly; hence they are all pre-selected by default. Please ensure all components are checked and then click the \"Next\" button. If users have already installed the corresponding components locally, they can skip the installation step and proceed directly to configuration. Step 3: It is recommended to proceed with the default process for the installation packages that appear and complete the installation as prompted. Step 4: Finally, we will reach the configuration interface. Users can choose to end the process directly at this point by selecting the default option, thus completing all installation steps.","title":"3.2 Configuration"},{"location":"section4/","text":"4 Software Page Overview \u672c\u7ae0\u5185\u5bb9 Welcome Page Dataset Parse Page Dataset Detail Page Dataset Browing Page Pipelines Page","title":"4 Software Page Overview"},{"location":"section4/#4-software-page-overview","text":"","title":"4 Software Page Overview"},{"location":"section4/#_1","text":"Welcome Page Dataset Parse Page Dataset Detail Page Dataset Browing Page Pipelines Page","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section4/subsection1/","text":"4.1 Welcome Page Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"Welcome Page"},{"location":"section4/subsection1/#41-welcome-page","text":"Upon opening the software, the initial welcome interface will be presented. The toolbar on the far left, from top to bottom, corresponds to the following pages: Explorer Page, DICOM Tags Page, Reports Page, Labels Page, Pipelines Page, and Plugins Page. The left drawer column will display the column information of the currently selected page. The majority of the right-hand side area constitutes the main interface, serving as the primary operational area for different pages.","title":"4.1 Welcome Page"},{"location":"section4/subsection2/","text":"4.2 Dataset Parse Page The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"Dataset Parse Page"},{"location":"section4/subsection2/#42-dataset-parse-page","text":"The Dataset Parse Page enables users to view the file structure of the currently selected folder and categorize and manage data files according to their needs.","title":"4.2 Dataset Parse Page"},{"location":"section4/subsection3/","text":"4.3 Dataset Detail Page The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"Dataset Detail Page"},{"location":"section4/subsection3/#43-dataset-detail-page","text":"The Dataset Detail Page will provide a detailed display of the data information within the dataset and offer image previews.","title":"4.3 Dataset Detail Page"},{"location":"section4/subsection4/","text":"4.4 Dataset Browing Page The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"Dataset Browing Page"},{"location":"section4/subsection4/#44-dataset-browing-page","text":"The Dataset Browsing Page provides an interface for browsing, editing, and annotating data. Users can perform operations such as adjusting contrast, rotating, and translating data.","title":"4.4 Dataset Browing Page"},{"location":"section4/subsection5/","text":"4.5 Pipelines Page The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"Pipelines Page"},{"location":"section4/subsection5/#45-pipelines-page","text":"The Pipelines Page provides a pipeline editing and running interface. Users can not only invoke MPF data processing workflows here but also customize data flows according to their requirements.","title":"4.5 Pipelines Page"},{"location":"section5/","text":"5 Welcome Page \u672c\u7ae0\u5185\u5bb9 New Dataset Recent Dataset","title":"5 Welcome Page"},{"location":"section5/#5-welcome-page","text":"","title":"5 Welcome Page"},{"location":"section5/#_1","text":"New Dataset Recent Dataset","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section5/subsection1/","text":"5.1 New Dataset To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"New Dataset"},{"location":"section5/subsection1/#51-new-dataset","text":"To create a new dataset, click on \"New Dataset\" on the welcome interface. A popup window will appear where users can fill in the necessary information. After completing the information, clicking \"CREATE\" will finalize the creation of the dataset.","title":"5.1 New Dataset"},{"location":"section5/subsection2/","text":"5.2 Recent Dataset If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"Recent Dataset"},{"location":"section5/subsection2/#52-recent-dataset","text":"If a dataset has already been created, users can directly open the established dataset by clicking on the name of the dataset under \"Recent.\"","title":"5.2 Recent Dataset"},{"location":"section6/","text":"6 Dataset Parse Page \u672c\u7ae0\u5185\u5bb9 Add Folder Prepare Dataset Refresh Manually Split Automatic Split Broom Parse Data swapper Settings","title":"6 Dataset Parse Page"},{"location":"section6/#6-dataset-parse-page","text":"","title":"6 Dataset Parse Page"},{"location":"section6/#_1","text":"Add Folder Prepare Dataset Refresh Manually Split Automatic Split Broom Parse Data swapper Settings","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section6/subsection1/","text":"6.1 Add Folder After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"Add Folder"},{"location":"section6/subsection1/#61-add-folder","text":"After creating a new folder, users will navigate to the dataset parsing page where they need to add the folder path of the data to be processed. By clicking on the \"ADD FOLDER\" button in the \"Explorer\" section on the left, users can select the local folder path.","title":"6.1 Add Folder"},{"location":"section6/subsection2/","text":"6.2 Prepare Dataset After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"Prepare Dataset"},{"location":"section6/subsection2/#62-prepare-dataset","text":"After adding the folder address, the \"PREPARE\" button on the main interface's right side will become active. At this point, users can directly click the button to trigger the default manual split and parse. Users can also click the three dots next to the button and select automatic split and parse mode. The interface after parsing is displayed below: Within the \"Explorer\" section, users can continue to add new folders.","title":"6.2 Prepare Dataset"},{"location":"section6/subsection3/","text":"6.3 Refresh The refresh button allows users to reload the file structure information within the currently added folders.","title":"Refresh"},{"location":"section6/subsection3/#63-refresh","text":"The refresh button allows users to reload the file structure information within the currently added folders.","title":"6.3 Refresh"},{"location":"section6/subsection4/","text":"6.4 Manually Split To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"Manually Split"},{"location":"section6/subsection4/#64-manually-split","text":"To manually split data, users can click on the white dividing line that separates the data. When the dividing line is selected, it will turn yellow. At this point, users can use the \"\u2191\" key on the keyboard to adjust the position of the dividing line, allowing for manual classification of the data. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.4 Manually Split"},{"location":"section6/subsection5/","text":"6.5 Automatic Split For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"Automatic Split"},{"location":"section6/subsection5/#65-automatic-split","text":"For automatic splitting, within the split button, select the desired number of categories, and then click the \"SPLIT\" button. Note: After completing the operation, you must click the \"CONFIRM\" button.","title":"6.5 Automatic Split"},{"location":"section6/subsection6/","text":"6.6 Broom Clicking the broom icon will hide the white dividing line.","title":"Broom"},{"location":"section6/subsection6/#66-broom","text":"Clicking the broom icon will hide the white dividing line.","title":"6.6 Broom"},{"location":"section6/subsection7/","text":"6.7 Parse Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"Parse"},{"location":"section6/subsection7/#67-parse","text":"Clicking the \"PARSE\" button will parse the data within the selected project. Once the parsing is complete, the \"Parse\" button will change to \"OPEN\".","title":"6.7 Parse"},{"location":"section6/subsection8/","text":"6.8 Data swapper After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it. 6.8.1 Query Data Users can query the data by setting different search criteria to retrieve specific information from the dataset. 6.8.2 Move Data For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"Data swapper"},{"location":"section6/subsection8/#68-data-swapper","text":"After completing the parsing process, a \"DATA SWAPPER\" button will appear in the bottom right corner of the page. Clicking this button will open a \"Data Retrieval\" interface where users can perform operations such as searching for data and moving it.","title":"6.8 Data swapper"},{"location":"section6/subsection8/#681-query-data","text":"Users can query the data by setting different search criteria to retrieve specific information from the dataset.","title":"6.8.1 Query Data"},{"location":"section6/subsection8/#682-move-data","text":"For the data retrieved, clicking on the arrow next to the series name allows you to view the data details. If you need to move the data, you can click the \"ADD\" button to add the data to the swap zone. Then, in the swap zone area, you can move or delete the data between projects.","title":"6.8.2 Move Data"},{"location":"section6/subsection9/","text":"6.9 Settings On the Settings page, users can perform data export and deletion. 6.9.1 Export The Export button provides various export options for users to choose export format. 6.9.2 Delete The delete button provides an additional verification step to prevent accidental deletions.","title":"Settings"},{"location":"section6/subsection9/#69-settings","text":"On the Settings page, users can perform data export and deletion.","title":"6.9 Settings"},{"location":"section6/subsection9/#691-export","text":"The Export button provides various export options for users to choose export format.","title":"6.9.1 Export"},{"location":"section6/subsection9/#692-delete","text":"The delete button provides an additional verification step to prevent accidental deletions.","title":"6.9.2 Delete"},{"location":"section7/","text":"7 Dataset Detail Page \u672c\u7ae0\u5185\u5bb9 Reports Labels Pipelines Attachments Table setting & Filters","title":"7 Dataset Detail Page"},{"location":"section7/#7-dataset-detail-page","text":"","title":"7 Dataset Detail Page"},{"location":"section7/#_1","text":"Reports Labels Pipelines Attachments Table setting & Filters","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section7/subsection1/","text":"7.1 Reports In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"Reports"},{"location":"section7/subsection1/#71-reports","text":"In the Reports section, users can record report information in the text input box located in the bottom left corner. Additionally, a \"Report\" column will be added to the table on the screen, making it convenient for users to directly view the data reports corresponding to each data.","title":"7.1 Reports"},{"location":"section7/subsection2/","text":"7.2 Labels In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"Labels"},{"location":"section7/subsection2/#72-labels","text":"In the Labels section, users can create or edit labels in the Label list located in the bottom left corner. Users can add labels to corresponding data by using buttons. Additionally, a \"Labels\" column will be added to the table on the screen, making it convenient for users to view the labels associated with each data. Each data can have multiple labels assigned to it.","title":"7.2 Labels"},{"location":"section7/subsection3/","text":"7.3 Pipelines In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"Pipelines"},{"location":"section7/subsection3/#73-pipelines","text":"In the Pipelines section, users can add pipelines to process data. In the Pipeline list located in the bottom left corner, users can use buttons to assign pipelines to corresponding data. This means that when running a pipeline, all data assigned to that pipeline will be processed. Additionally, the table on the screen will include new columns for \"Pipelines\" and \"Post-processing outputs,\" making it easy for users to select data to execute specific post-processing workflows and review processing results","title":"7.3 Pipelines"},{"location":"section7/subsection4/","text":"7.4 Attachments In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"Attachments"},{"location":"section7/subsection4/#74-attachments","text":"In the Attachments section, users can select attachments from the bottom left corner and assign them to corresponding data by using buttons. Additionally, a new column for \"Attachments\" will be added to the table on the screen.","title":"7.4 Attachments"},{"location":"section7/subsection5/","text":"7.5 Table setting & Filters The table can display multiple annotation information and users can also filter data through filters.","title":"Table setting & Filters"},{"location":"section7/subsection5/#75-table-setting-filters","text":"The table can display multiple annotation information and users can also filter data through filters.","title":"7.5 Table setting &amp; Filters"},{"location":"section8/","text":"8 Dataset Browing Page \u672c\u7ae0\u5185\u5bb9 Image Interface Data Interaction & Toolbar","title":"8 Dataset Browing Page"},{"location":"section8/#8-dataset-browing-page","text":"","title":"8 Dataset Browing Page"},{"location":"section8/#_1","text":"Image Interface Data Interaction & Toolbar","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section8/subsection1/","text":"8.1 Image Interface 8.1.1 Reset Camera Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings. 8.1.2 Data Info In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"Image Interface"},{"location":"section8/subsection1/#81-image-interface","text":"","title":"8.1 Image Interface"},{"location":"section8/subsection1/#811-reset-camera","text":"Both the top left corner and the right toolbar in the interface provide a \"Reset Camera\" button, which allows users to reset all camera settings.","title":"8.1.1 Reset Camera"},{"location":"section8/subsection1/#812-data-info","text":"In the top right corner of the image interface, there is an icon that can display basic information about the image.","title":"8.1.2 Data Info"},{"location":"section8/subsection2/","text":"8.2 Data Interaction & Toolbar 8.2.1 Interaction Info List In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering. 8.2.2 Layout Selection On this page, users can select the layout interface and achieve 3D reconstruction. 8.2.3 Window/Level (Contrast) This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width. 8.2.4 Pan To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view. 8.2.5 Zoom To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out. 8.2.6 Crosshair To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position. 8.2.7 Paint (Segmentation) In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image. 8.2.8 Rectangle (Measurement) In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI. 8.2.9 Polygon (Measurement) Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area. 8.2.10 Ruler (Measurement) Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points. 8.2.11 3D Crop Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"Data Interaction & Toolbar"},{"location":"section8/subsection2/#82-data-interaction-toolbar","text":"","title":"8.2 Data Interaction &amp; Toolbar"},{"location":"section8/subsection2/#821-interaction-info-list","text":"In the toolbar on the right-hand side, the first button is \"Interaction Info List\", which consists of two sections: \"Annotation\" and \"Rendering\". Annotation: This module contains two sections: one part is about segment information, and the other part is about measurements information. When the user is using the Paint tool, this list allows for setting properties of Paint tool. The upper part allows users to select the brush or eraser for drawing and adjust the brush size and ROI area transparency. The lower part is for managing multiple ROI groups, where each ROI group can be custom-named, hidden, downloaded, and deleted. The ROI group colors can be added, selected, and named. When the user is using the measurement tool, users can also view completed annotations in this list. For completed measurements, users can perform operations such as reveal slice, visibility toggle, and delete. Rendering: The module allows users to render data and adjust settings for cinematic rendering.","title":"8.2.1 Interaction Info List"},{"location":"section8/subsection2/#822-layout-selection","text":"On this page, users can select the layout interface and achieve 3D reconstruction.","title":"8.2.2 Layout Selection"},{"location":"section8/subsection2/#823-windowlevel-contrast","text":"This button enables contrast adjustment functionality. We have incorporated default settings for image reading, along with four additional options: Full Range, Low Contrast, Medium Contrast, and High Contrast. Users can conveniently select these options based on their requirements. Users can also hold down the left mouse button on the image and move up and down to adjust the window level, and left and right to adjust the window width.","title":"8.2.3 Window/Level (Contrast)"},{"location":"section8/subsection2/#824-pan","text":"To pan, click on the Pan button, then hold down the left mouse button on the image and drag it to move the view.","title":"8.2.4 Pan"},{"location":"section8/subsection2/#825-zoom","text":"To zoom, click on the Zoom button in the toolbar, then hold down the left mouse button on the image and move up and down to zoom in and out.","title":"8.2.5 Zoom"},{"location":"section8/subsection2/#826-crosshair","text":"To use the Crosshair feature, click on the Crosshair button in the toolbar. A cross-shaped crosshair will track the mouse cursor on the image. Click to lock the crosshair at the desired position.","title":"8.2.6 Crosshair"},{"location":"section8/subsection2/#827-paint-segmentation","text":"In the toolbar, choose the Paint button to utilize the brush tool for selecting Regions of Interest (ROI) on the image.","title":"8.2.7 Paint (Segmentation)"},{"location":"section8/subsection2/#828-rectangle-measurement","text":"In the Toolbar, click on the Rectangle button, then utilize the brush tool to select the ROI area on the image. Begin by selecting the starting point, and then confirm the endpoint to finish drawing a rectangular ROI.","title":"8.2.8 Rectangle (Measurement)"},{"location":"section8/subsection2/#829-polygon-measurement","text":"Within the Toolbar, locate and select the Polygon tool. Utilize the brush tool to outline the ROI on the image. Begin by choosing an initial point, then confirm each subsequent point by clicking the mouse. Continue this process until the final point coincides with the starting point, thus forming a closed shape and completing the drawing of the Polygon ROI area.","title":"8.2.9 Polygon (Measurement)"},{"location":"section8/subsection2/#8210-ruler-measurement","text":"Select the Ruler button in the Toolbar, then use the tool to choose a starting point on the image and confirm the endpoint to measure the distance between the two points.","title":"8.2.10 Ruler (Measurement)"},{"location":"section8/subsection2/#8211-3d-crop","text":"Select the 3D Crop button in the Toolbar, then adjust the corner, edge, and side markers in the 3D window, and manipulate the edges of the bounding box overlaid on the data in the 2D windows to make precise adjustments.","title":"8.2.11 3D Crop"},{"location":"section9/","text":"9 Plugin Page \u672c\u7ae0\u5185\u5bb9 Node Plugin","title":"9 Plugin Page"},{"location":"section9/#9-plugin-page","text":"","title":"9 Plugin Page"},{"location":"section9/#_1","text":"Node Plugin","title":"\u672c\u7ae0\u5185\u5bb9"},{"location":"section9/subsection1/","text":"9.1 Node 9.1.1 Varieties of Nodes The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file. 9.1.2 Add Node Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow. 9.2.2 Node Setting Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings. 9.2.1 Node status description The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"Node"},{"location":"section9/subsection1/#91-node","text":"","title":"9.1 Node"},{"location":"section9/subsection1/#911-varieties-of-nodes","text":"The node system currently provides the following categories: Input, Plugins, Converters, Preview, and Output. Input Node: This serves as the entry point for loading data that requires processing. Each pipeline must have exactly one Input Node - no more, no less. Plugin Nodes: These are algorithmic nodes that execute either pre-configured or user-defined Python code to perform computational operations on the data. Converter Nodes: These nodes handle data format conversions and transformations. Preview Nodes: These invoke preview interface, allowing users to visualize both the raw data and intermediate data generated during the processing pipeline. Output Node: This node determines whether and in what format the results should be saved to file.","title":"9.1.1 Varieties of Nodes"},{"location":"section9/subsection1/#912-add-node","text":"Right-click on any blank area of the workspace to access the main menu operations. Select the desired option to add it to workflow.","title":"9.1.2 Add Node"},{"location":"section9/subsection1/#922-node-setting","text":"Right-click on a node in the workspace to access node-specific menu operations for the currently selected node. The Toolbar functions from left to right are: Reset Color, Pin, Delete, and Update Definition.The options panel on the right provides specific controls corresponding to each selected item's properties and settings.","title":"9.2.2 Node Setting"},{"location":"section9/subsection1/#921-node-status-description","text":"The workflow consists of multiple nodes, each of which exhibits distinct visual states during editing and execution phases. During Editing: Nodes can display three states: Unselected nodes appear without borders Selected nodes are highlighted with a white border, and their associated input/output links are also displayed in white Nodes with initialization errors are marked with a red border, indicating the need for definition correction During Execution: Nodes transition through four distinct states: Current: Indicated by a blue border, representing the node currently being processed Pending: Marked with a yellow border, signifying nodes awaiting processing Done: Displayed with a green border, denoting successfully completed nodes Error: Highlighted with a red border, indicating nodes that encountered processing exceptions The visual state system employs consistent color coding to provide immediate feedback on node status, facilitating efficient workflow monitoring and management.","title":"9.2.1 Node status description"},{"location":"section9/subsection2/","text":"9.2 Plugin To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"Plugin"},{"location":"section9/subsection2/#92-plugin","text":"To add a new plugin in the Plugin section, two files are required: A configuration file in JSON format that describes and defines the plugin's specifications and parameters. A Python file containing the executable code for data processing. Users can input these files in two ways: Drag and drop the files directly from their local system to the input area Click the input field to open a file selection dialog Once both files are selected, click \"Import\" to complete the upload process. Note that both files must conform to specific format requirements. If the format requirements are not met, error messages will be displayed, indicating that modifications to the plugin content are necessary. After successful import, the newly imported plugin will appear in the plugin list below. To utilize this newly added plugin in the pipeline interface, right-click and select \"Reload Workflow\". Important: Please ensure you save any existing modifications before reloading, as this action will reset unsaved changes.","title":"9.2 Plugin"}]}